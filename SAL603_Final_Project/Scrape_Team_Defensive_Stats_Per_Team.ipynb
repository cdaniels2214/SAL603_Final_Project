{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "382cae1e-a8ea-4062-a3fc-f5a9ebfbca48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Passing - Missing teams: 3\n",
      "‚úÖ Rushing - Missing teams: 6\n",
      "Scraping passing defense stats for Washington (2024) - https://cfbstats.com/2024/team/756/passing/defense/split.html\n",
      "Scraping passing defense stats for Virginia Tech (2022) - https://cfbstats.com/2022/team/742/passing/defense/split.html\n",
      "Scraping passing defense stats for South Alabama (2023) - https://cfbstats.com/2023/team/646/passing/defense/split.html\n",
      "Scraping rushing defense stats for Wake Forest (2023) - https://cfbstats.com/2023/team/749/rushing/defense/split.html\n",
      "Scraping rushing defense stats for UAB (2024) - https://cfbstats.com/2024/team/9/rushing/defense/split.html\n",
      "Scraping rushing defense stats for Virginia Tech (2022) - https://cfbstats.com/2022/team/742/rushing/defense/split.html\n",
      "Scraping rushing defense stats for Tulsa (2023) - https://cfbstats.com/2023/team/719/rushing/defense/split.html\n",
      "Scraping rushing defense stats for Texas Tech (2022) - https://cfbstats.com/2022/team/700/rushing/defense/split.html\n",
      "Scraping rushing defense stats for Toledo (2022) - https://cfbstats.com/2022/team/709/rushing/defense/split.html\n",
      "‚úÖ Added 3 new records to C:\\Users\\Christopher\\OneDrive - Syracuse University\\PythonSportAnalytics\\Section_8\\Final_Project\\CSV_Files\\cfbstats_team_passing_stats_defense_2022_2024.csv\n",
      "‚úÖ Added 6 new records to C:\\Users\\Christopher\\OneDrive - Syracuse University\\PythonSportAnalytics\\Section_8\\Final_Project\\CSV_Files\\cfbstats_team_rushing_stats_defense_2022_2024.csv\n",
      "\n",
      "üéØ Missing teams have been scraped and added to the respective files.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "\n",
    "# Define output directory\n",
    "base_dir = r\"C:\\Users\\Christopher\\OneDrive - Syracuse University\\PythonSportAnalytics\\Section_8\\Final_Project\\CSV_Files\"\n",
    "\n",
    "# Load the existing team data CSV for list of teams, IDs, etc\n",
    "team_data_file = os.path.join(base_dir, \"cfbstats_teams_2022_2024.csv\")\n",
    "if not os.path.exists(team_data_file):\n",
    "    print(\"Team data file not found!\")\n",
    "    exit()\n",
    "\n",
    "df_teams = pd.read_csv(team_data_file)\n",
    "\n",
    "# User-Agent list\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "]\n",
    "\n",
    "REFERERS = [\n",
    "    \"https://www.google.com/\",\n",
    "    \"https://www.bing.com/\",\n",
    "    \"https://www.yahoo.com/\",\n",
    "    \"https://duckduckgo.com/\"\n",
    "]\n",
    "\n",
    "# File paths for defense stats\n",
    "passing_file = os.path.join(base_dir, \"cfbstats_team_passing_stats_defense_2022_2024.csv\")\n",
    "rushing_file = os.path.join(base_dir, \"cfbstats_team_rushing_stats_defense_2022_2024.csv\")\n",
    "\n",
    "# Load existing data to check for missing teams\n",
    "df_passing = pd.read_csv(passing_file) if os.path.exists(passing_file) else pd.DataFrame()\n",
    "df_rushing = pd.read_csv(rushing_file) if os.path.exists(rushing_file) else pd.DataFrame()\n",
    "\n",
    "# Function to determine missing teams, if any, from initial scrape\n",
    "def get_missing_teams(df, stat_type):\n",
    "    existing_teams = set(zip(df[\"Team\"], df[\"Year\"])) if not df.empty else set()\n",
    "    all_teams = set(zip(df_teams[\"Team\"], df_teams[\"Year\"]))\n",
    "    missing_teams = all_teams - existing_teams  # Find teams not yet scraped\n",
    "    print(f\"‚úÖ {stat_type.capitalize()} - Missing teams: {len(missing_teams)}\")\n",
    "    return missing_teams\n",
    "\n",
    "missing_passing_teams = get_missing_teams(df_passing, \"passing\")\n",
    "missing_rushing_teams = get_missing_teams(df_rushing, \"rushing\")\n",
    "\n",
    "def scrape_defensive_stats(team_name, year, team_id, stat_type):\n",
    "    # Construct URL based on stat type\n",
    "    url = f\"https://cfbstats.com/{year}/team/{team_id}/{stat_type}/defense/split.html\"\n",
    "    print(f\"Scraping {stat_type} defense stats for {team_name} ({year}) - {url}\")\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": random.choice(USER_AGENTS),\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Referer\": random.choice(REFERERS),\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"‚ùå Failed to fetch {url} for {team_name} ({year}) (Error: {e})\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Locate the stats table\n",
    "    table = soup.find(\"table\")\n",
    "    if not table:\n",
    "        print(f\"‚ùå No stats table found for {team_name} ({year}) in {stat_type} defense\")\n",
    "        return None\n",
    "    \n",
    "    rows = table.find_all(\"tr\")\n",
    "    \n",
    "    # Extract header row\n",
    "    headers = [th.text.strip() for th in rows[0].find_all(\"th\")]\n",
    "    \n",
    "    # Extract only the first data row\n",
    "    first_data_row = rows[1].find_all(\"td\") if len(rows) > 1 else []\n",
    "    \n",
    "    if not first_data_row:\n",
    "        print(f\"‚ùå No valid data row found for {team_name} ({year}) in {stat_type} defense\")\n",
    "        return None\n",
    "    \n",
    "    # Extract values from the first row\n",
    "    row_values = [td.text.strip() for td in first_data_row]\n",
    "    \n",
    "    # Prepare dictionary for DataFrame\n",
    "    data_dict = dict(zip(headers, row_values))\n",
    "    data_dict[\"Team\"] = team_name\n",
    "    data_dict[\"Year\"] = year\n",
    "    data_dict[\"Team ID\"] = team_id\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "# Prepare data storage for teams\n",
    "passing_data = []\n",
    "rushing_data = []\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel scraping (goes faster)\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = {}\n",
    "    for team_name, year in missing_passing_teams:\n",
    "        team_id = df_teams[(df_teams[\"Team\"] == team_name) & (df_teams[\"Year\"] == year)][\"Team ID\"].values[0]\n",
    "        futures[executor.submit(scrape_defensive_stats, team_name, year, team_id, \"passing\")] = (\"passing\", team_name)\n",
    "    \n",
    "    for team_name, year in missing_rushing_teams:\n",
    "        team_id = df_teams[(df_teams[\"Team\"] == team_name) & (df_teams[\"Year\"] == year)][\"Team ID\"].values[0]\n",
    "        futures[executor.submit(scrape_defensive_stats, team_name, year, team_id, \"rushing\")] = (\"rushing\", team_name)\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                stat_type, team_name = futures[future]\n",
    "                if stat_type == \"passing\":\n",
    "                    passing_data.append(result)\n",
    "                else:\n",
    "                    rushing_data.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error scraping {futures[future][1]}: {e}\")\n",
    "\n",
    "# Append new data to existing CSVs if teams were missed in initial scraping\n",
    "for stat_type, data, file_path in [(\"passing\", passing_data, passing_file), (\"rushing\", rushing_data, rushing_file)]:\n",
    "    if data:\n",
    "        df_new = pd.DataFrame(data)\n",
    "\n",
    "        # Ensure consistent column ordering\n",
    "        col_order = [\"Team\", \"Year\", \"Team ID\"] + [col for col in df_new.columns if col not in [\"Team\", \"Year\", \"Team ID\"]]\n",
    "        df_new = df_new[col_order]\n",
    "\n",
    "        # Sort by Team (A-Z) and Year (Descending)\n",
    "        df_new = df_new.sort_values(by=[\"Team\", \"Year\"], ascending=[True, False])\n",
    "\n",
    "        # Append new data to existing file\n",
    "        df_new.to_csv(file_path, mode=\"a\", header=not os.path.exists(file_path), index=False)\n",
    "        print(f\"‚úÖ Added {len(df_new)} new records to {file_path}\")\n",
    "\n",
    "print(\"\\n‚úÖ Missing teams have been scraped and added to the respective files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69428a7b-2339-44cd-b73b-5ac51f7f31d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ cfbstats_team_passing_stats_defense_2022_2024.csv: Total unique teams: 127\n",
      "‚úÖ cfbstats_team_passing_stats_defense_2022_2024.csv: All teams have exactly 3 entries (one per year for 2024, 2023, 2022).\n",
      "‚úÖ cfbstats_team_rushing_stats_defense_2022_2024.csv: Total unique teams: 127\n",
      "‚úÖ cfbstats_team_rushing_stats_defense_2022_2024.csv: All teams have exactly 3 entries (one per year for 2024, 2023, 2022).\n"
     ]
    }
   ],
   "source": [
    "#Verification that each team has one entry per season\n",
    "# Files to check\n",
    "passing_file = os.path.join(base_dir, \"cfbstats_team_passing_stats_defense_2022_2024.csv\")\n",
    "rushing_file = os.path.join(base_dir, \"cfbstats_team_rushing_stats_defense_2022_2024.csv\")\n",
    "\n",
    "# Load the datasets\n",
    "df_passing = pd.read_csv(passing_file)\n",
    "df_rushing = pd.read_csv(rushing_file)\n",
    "\n",
    "# Function to validate the dataset\n",
    "def validate_file(df, file_name):\n",
    "    # Count unique teams\n",
    "    unique_teams = df[\"Team\"].nunique()\n",
    "    print(f\"‚úÖ {file_name}: Total unique teams: {unique_teams}\")\n",
    "\n",
    "    # Verify that each team has exactly 3 entries (one for each year: 2024, 2023, 2022)\n",
    "    team_year_counts = df[df[\"Year\"].isin([2024, 2023, 2022])].groupby(\"Team\")[\"Year\"].nunique()\n",
    "    incorrect_teams = team_year_counts[team_year_counts != 3]\n",
    "\n",
    "    if incorrect_teams.empty:\n",
    "        print(f\"‚úÖ {file_name}: All teams have exactly 3 entries (one per year for 2024, 2023, 2022).\")\n",
    "    else:\n",
    "        print(f\"‚ùå {file_name}: The following teams do not have exactly 3 entries:\")\n",
    "        print(incorrect_teams)\n",
    "\n",
    "# Validate both files\n",
    "validate_file(df_passing, \"cfbstats_team_passing_stats_defense_2022_2024.csv\")\n",
    "validate_file(df_rushing, \"cfbstats_team_rushing_stats_defense_2022_2024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358f22d-689e-4939-8a96-842c081ac889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
